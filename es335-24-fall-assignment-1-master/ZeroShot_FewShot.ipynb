{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate Zero shot and Few shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_groq.chat_models import ChatGroq\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq API and Models\n",
    "Groq_Token = os.getenv('GROQ_API_KEY')  # Do not share this key with anyone\n",
    "\n",
    "groq_models = {\"llama3-70b\": \"llama3-70b-8192\", \"mixtral\": \"mixtral-8x7b-32768\", \"gemma-7b\": \"gemma-7b-it\",\"llama3.1-70b\":\"llama-3.1-70b-versatile\",\"llama3-8b\":\"llama3-8b-8192\",\"llama3.1-8b\":\"llama-3.1-8b-instant\",\"gemma-9b\":\"gemma2-9b-it\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE : DO NOT SHARE THE API KEY WITH ANYONE. DO NOT COMMIT THE API KEY TO GITHUB.**\n",
    "\n",
    "Always do a sanity check before committing the code to github. If the key is found in the code, you will be penalized with a 1 marks deduction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM Working Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Label: Neutral\n",
      "\n",
      "Explanation: \n",
      "The sentence contains both positive and negative sentiments. The phrase \"The product quality is amazing\" is positive, indicating satisfaction with the product. However, the phrase \"the delivery was delayed\" is negative, indicating a problem with the delivery process. The phrase \"However I am happy with the customer service\" is also positive, indicating satisfaction with the customer service. Since the sentence contains both positive and negative sentiments, the overall sentiment is neutral.\n"
     ]
    }
   ],
   "source": [
    "# Statement\n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts\n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model.\n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'.\n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "# To use Groq LLMs\n",
    "model_name = \"llama3.1-8b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(api_key=Groq_Token, model=groq_models[model_name], temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Human Activity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './Combined/Test'\n",
    "activities = [\"LAYING\", \"SITTING\", \"STANDING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are provided with accelerometer data in the X, Y, and Z directions, recorded during different human activities. The activities can be one of the following: 'LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS', or 'WALKING_UPSTAIRS'. Based on the input data from these three axes, predict the corresponding activity label without additional explanation. No code is to be produced for this, rather the final activity label based on the analysis from the different directional accelerometer data\"),\n",
    "    (\"user\", \"The accelerometer readings are: X: {x_data}, Y: {y_data}, Z: {z_data}. What activity does this data represent?\")\n",
    "])\n",
    "\n",
    "chain = chat_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 75\n",
    "system_prompt = {}\n",
    "prompts = []\n",
    "\n",
    "for activity in activities:\n",
    "    activity_path = os.path.join(path, activity)\n",
    "\n",
    "    listings = [f for f in os.listdir(activity_path) if f.endswith('.csv')]\n",
    "\n",
    "    subjects = random.sample(listings, 1)  # one test subject for each activity\n",
    "\n",
    "    for i in range(len(subjects)):\n",
    "        file_path = os.path.join(activity_path, subjects[i])\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        x = df['accx'][:n_samples].apply(lambda val: round(val, 2)).tolist()\n",
    "        y = df['accy'][:n_samples].apply(lambda val: round(val, 2)).tolist()\n",
    "        z = df['accz'][:n_samples].apply(lambda val: round(val, 2)).tolist()\n",
    "\n",
    "        prompts.append({\n",
    "            \"value\": activity,\n",
    "            \"data\": {\n",
    "                \"x_data\": x,\n",
    "                \"y_data\": y,\n",
    "                \"z_data\": z\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: LAYING\n",
      "Prediction:  Based on the provided accelerometer data, the activity is 'WALKING'.\n",
      "\n",
      "Ground Truth: SITTING\n",
      "Prediction:  Based on the provided accelerometer data, the activity is 'LAYING'.\n",
      "\n",
      "Ground Truth: STANDING\n",
      "Prediction:  Based on the provided accelerometer data, the activity is 'WALKING'.\n",
      "\n",
      "Ground Truth: WALKING\n",
      "Prediction:  Based on the provided accelerometer data, the activity is 'WALKING'.\n",
      "\n",
      "Ground Truth: WALKING_DOWNSTAIRS\n",
      "Prediction:  Based on the provided accelerometer data, the activity is 'WALKING'.\n",
      "\n",
      "Ground Truth: WALKING_UPSTAIRS\n",
      "Prediction:  Based on the provided accelerometer data, the activity is 'WALKING'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "  answer = chain.invoke(prompt['data'])\n",
    "  print(\"Ground Truth:\", prompt['value'])\n",
    "  print(\"Prediction: \", answer.content)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Few Shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLM Working Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Positive\n",
      "\n",
      "Explanation: Although the sentence mentions a negative aspect (\"the delivery was delayed\"), the positive sentiments expressed in the sentence (\"The product quality is amazing\" and \"I am happy with the customer service\") outweigh the negative one, resulting in an overall positive sentiment.\n"
     ]
    }
   ],
   "source": [
    "# Statement\n",
    "sentence = \"The product quality is amazing but the delivery was delayed. However I am happy with the customer service.\"\n",
    "\n",
    "# System Prompts\n",
    "query = f\"\"\"\n",
    "* You are a sentiment analysis model.\n",
    "* Your task is to analyze the sentiment expressed in the given text and classify it as 'positive', 'negative', or 'neutral'.\n",
    "* Provide the sentiment label and, if necessary, a brief explanation of your reasoning.\n",
    "\n",
    "Here are few examples:\n",
    "1. Sentence: 'The customer service was excellent, and I received my order quickly.'\n",
    "Sentiment: Positive\n",
    "\n",
    "2. Sentence: 'The food was bland and the service was slow.'\n",
    "Sentiment: Negative\n",
    "\n",
    "3. Sentence: 'The product is okay, but it's not worth the price.'\n",
    "Sentiment: Neutral\n",
    "\n",
    "Sentence: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "# To use Groq LLMs\n",
    "model_name = \"llama3-70b\" # We can choose any model from the groq_models dictionary\n",
    "llm = ChatGroq(model=groq_models[model_name], api_key=Groq_Token, temperature=0)\n",
    "answer = llm.invoke(query)\n",
    "\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Human Activity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test = './Combined/Test'\n",
    "path_train = './Combined/Train'\n",
    "activities = [\"LAYING\", \"SITTING\", \"STANDING\", \"WALKING\", \"WALKING_DOWNSTAIRS\", \"WALKING_UPSTAIRS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are provided with accelerometer data in the X, Y, and Z directions, recorded during different human activities. The activities can be one of the following: 'LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS', or 'WALKING_UPSTAIRS'. Based on the input data from these three axes, predict the corresponding activity label without additional explanation. No code is to be produced for this, rather the final activity label based on the analysis from the different directional accelerometer data. Here are a few examples:\"),\n",
    "    (\"system\", \"Example 1 - Activity: LAYING, {LAYING}\"),\n",
    "    (\"system\", \"Example 2 - Activity: SITTING, {SITTING}\"),\n",
    "    (\"system\", \"Example 3 - Activity: STANDING, {STANDING}\"),\n",
    "    (\"system\", \"Example 4 - Activity: WALKING, {WALKING}\"),\n",
    "    (\"system\", \"Example 5 - Activity: WALKING_DOWNSTAIRS, {WALKING_DOWNSTAIRS}\"),\n",
    "    (\"system\", \"Example 6 - Activity: WALKING_UPSTAIRS, {WALKING_UPSTAIRS}\"),\n",
    "    (\"user\", \"The accelerometer readings are: X: {x_data}, Y: {y_data}, Z: {z_data}. What activity does this data represent?\")\n",
    "])\n",
    "\n",
    "chain = chat_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing system prompt with examples for few shot\n",
    "for activity in activities:\n",
    "    activity_path_train = os.path.join(path_train, activity)\n",
    "    listings_train = [f for f in os.listdir(activity_path_train) if f.endswith('.csv')]\n",
    "\n",
    "    subjects_train = random.sample(listings_train, 1)\n",
    "\n",
    "    for i in range(len(subjects_train)):\n",
    "        file_path = os.path.join(activity_path, subjects[i])\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        x = df['accx'][:n_samples].apply(lambda val: round(val, 2)).tolist()\n",
    "        y = df['accy'][:n_samples].apply(lambda val: round(val, 2)).tolist()\n",
    "        z = df['accz'][:n_samples].apply(lambda val: round(val, 2)).tolist()\n",
    "\n",
    "        system_prompt[activity] = f\"X: {x}, Y: {y}, Z: {z}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LAYING': 'X: [0.64, 0.67, 0.69, 0.72, 0.82, 0.91, 0.96, 0.97, 0.92, 0.87, 0.83, 0.88, 0.97, 1.02, 1.02, 1.0, 1.04, 1.12, 1.23, 1.36, 1.4, 1.42, 1.4, 1.21, 1.04, 1.02, 1.01, 1.0, 1.01, 1.0, 0.95, 0.92, 0.87, 0.79, 0.72, 0.66, 0.64, 0.63, 0.64, 0.73, 0.85, 0.95, 0.99, 1.0, 1.02, 1.02, 1.01, 1.02, 1.0, 0.99, 1.0, 1.04, 1.09, 1.12, 1.19, 1.41, 1.65, 1.7, 1.63, 1.58, 1.43, 1.17, 0.99, 0.98, 1.08, 1.14, 1.06, 0.97, 0.96, 0.92, 0.8, 0.66, 0.57, 0.53, 0.55], Y: [-0.18, -0.21, -0.16, -0.14, -0.16, -0.19, -0.23, -0.24, -0.23, -0.16, -0.08, -0.05, -0.14, -0.23, -0.19, -0.18, -0.21, -0.23, -0.33, -0.41, -0.35, -0.32, -0.38, -0.43, -0.49, -0.5, -0.43, -0.38, -0.33, -0.28, -0.24, -0.16, -0.13, -0.17, -0.18, -0.2, -0.2, -0.19, -0.21, -0.23, -0.24, -0.18, -0.07, -0.03, -0.06, -0.06, -0.03, -0.02, -0.03, -0.02, -0.04, -0.09, -0.17, -0.19, -0.13, -0.14, -0.24, -0.35, -0.44, -0.52, -0.52, -0.42, -0.38, -0.37, -0.33, -0.39, -0.39, -0.32, -0.27, -0.2, -0.16, -0.11, -0.08, -0.13, -0.12], Z: [0.05, 0.07, 0.11, 0.09, 0.08, 0.14, 0.2, 0.25, 0.26, 0.26, 0.26, 0.22, 0.19, 0.23, 0.25, 0.22, 0.17, 0.15, 0.19, 0.26, 0.29, 0.31, 0.32, 0.26, 0.18, 0.12, 0.08, 0.1, 0.1, 0.06, 0.05, 0.06, 0.07, 0.06, 0.05, 0.04, -0.0, -0.01, 0.01, 0.02, 0.03, 0.04, 0.04, 0.03, 0.01, 0.03, 0.06, 0.07, 0.06, 0.04, 0.03, 0.03, 0.02, 0.02, -0.0, -0.06, -0.1, -0.07, -0.03, -0.01, -0.03, -0.07, -0.07, -0.02, 0.02, 0.03, 0.05, 0.08, 0.07, 0.02, 0.01, 0.01, -0.0, 0.0, 0.02]',\n",
       " 'SITTING': 'X: [0.64, 0.67, 0.69, 0.72, 0.82, 0.91, 0.96, 0.97, 0.92, 0.87, 0.83, 0.88, 0.97, 1.02, 1.02, 1.0, 1.04, 1.12, 1.23, 1.36, 1.4, 1.42, 1.4, 1.21, 1.04, 1.02, 1.01, 1.0, 1.01, 1.0, 0.95, 0.92, 0.87, 0.79, 0.72, 0.66, 0.64, 0.63, 0.64, 0.73, 0.85, 0.95, 0.99, 1.0, 1.02, 1.02, 1.01, 1.02, 1.0, 0.99, 1.0, 1.04, 1.09, 1.12, 1.19, 1.41, 1.65, 1.7, 1.63, 1.58, 1.43, 1.17, 0.99, 0.98, 1.08, 1.14, 1.06, 0.97, 0.96, 0.92, 0.8, 0.66, 0.57, 0.53, 0.55], Y: [-0.18, -0.21, -0.16, -0.14, -0.16, -0.19, -0.23, -0.24, -0.23, -0.16, -0.08, -0.05, -0.14, -0.23, -0.19, -0.18, -0.21, -0.23, -0.33, -0.41, -0.35, -0.32, -0.38, -0.43, -0.49, -0.5, -0.43, -0.38, -0.33, -0.28, -0.24, -0.16, -0.13, -0.17, -0.18, -0.2, -0.2, -0.19, -0.21, -0.23, -0.24, -0.18, -0.07, -0.03, -0.06, -0.06, -0.03, -0.02, -0.03, -0.02, -0.04, -0.09, -0.17, -0.19, -0.13, -0.14, -0.24, -0.35, -0.44, -0.52, -0.52, -0.42, -0.38, -0.37, -0.33, -0.39, -0.39, -0.32, -0.27, -0.2, -0.16, -0.11, -0.08, -0.13, -0.12], Z: [0.05, 0.07, 0.11, 0.09, 0.08, 0.14, 0.2, 0.25, 0.26, 0.26, 0.26, 0.22, 0.19, 0.23, 0.25, 0.22, 0.17, 0.15, 0.19, 0.26, 0.29, 0.31, 0.32, 0.26, 0.18, 0.12, 0.08, 0.1, 0.1, 0.06, 0.05, 0.06, 0.07, 0.06, 0.05, 0.04, -0.0, -0.01, 0.01, 0.02, 0.03, 0.04, 0.04, 0.03, 0.01, 0.03, 0.06, 0.07, 0.06, 0.04, 0.03, 0.03, 0.02, 0.02, -0.0, -0.06, -0.1, -0.07, -0.03, -0.01, -0.03, -0.07, -0.07, -0.02, 0.02, 0.03, 0.05, 0.08, 0.07, 0.02, 0.01, 0.01, -0.0, 0.0, 0.02]',\n",
       " 'WALKING_DOWNSTAIRS': 'X: [0.64, 0.67, 0.69, 0.72, 0.82, 0.91, 0.96, 0.97, 0.92, 0.87, 0.83, 0.88, 0.97, 1.02, 1.02, 1.0, 1.04, 1.12, 1.23, 1.36, 1.4, 1.42, 1.4, 1.21, 1.04, 1.02, 1.01, 1.0, 1.01, 1.0, 0.95, 0.92, 0.87, 0.79, 0.72, 0.66, 0.64, 0.63, 0.64, 0.73, 0.85, 0.95, 0.99, 1.0, 1.02, 1.02, 1.01, 1.02, 1.0, 0.99, 1.0, 1.04, 1.09, 1.12, 1.19, 1.41, 1.65, 1.7, 1.63, 1.58, 1.43, 1.17, 0.99, 0.98, 1.08, 1.14, 1.06, 0.97, 0.96, 0.92, 0.8, 0.66, 0.57, 0.53, 0.55], Y: [-0.18, -0.21, -0.16, -0.14, -0.16, -0.19, -0.23, -0.24, -0.23, -0.16, -0.08, -0.05, -0.14, -0.23, -0.19, -0.18, -0.21, -0.23, -0.33, -0.41, -0.35, -0.32, -0.38, -0.43, -0.49, -0.5, -0.43, -0.38, -0.33, -0.28, -0.24, -0.16, -0.13, -0.17, -0.18, -0.2, -0.2, -0.19, -0.21, -0.23, -0.24, -0.18, -0.07, -0.03, -0.06, -0.06, -0.03, -0.02, -0.03, -0.02, -0.04, -0.09, -0.17, -0.19, -0.13, -0.14, -0.24, -0.35, -0.44, -0.52, -0.52, -0.42, -0.38, -0.37, -0.33, -0.39, -0.39, -0.32, -0.27, -0.2, -0.16, -0.11, -0.08, -0.13, -0.12], Z: [0.05, 0.07, 0.11, 0.09, 0.08, 0.14, 0.2, 0.25, 0.26, 0.26, 0.26, 0.22, 0.19, 0.23, 0.25, 0.22, 0.17, 0.15, 0.19, 0.26, 0.29, 0.31, 0.32, 0.26, 0.18, 0.12, 0.08, 0.1, 0.1, 0.06, 0.05, 0.06, 0.07, 0.06, 0.05, 0.04, -0.0, -0.01, 0.01, 0.02, 0.03, 0.04, 0.04, 0.03, 0.01, 0.03, 0.06, 0.07, 0.06, 0.04, 0.03, 0.03, 0.02, 0.02, -0.0, -0.06, -0.1, -0.07, -0.03, -0.01, -0.03, -0.07, -0.07, -0.02, 0.02, 0.03, 0.05, 0.08, 0.07, 0.02, 0.01, 0.01, -0.0, 0.0, 0.02]',\n",
       " 'WALKING_UPSTAIRS': 'X: [0.64, 0.67, 0.69, 0.72, 0.82, 0.91, 0.96, 0.97, 0.92, 0.87, 0.83, 0.88, 0.97, 1.02, 1.02, 1.0, 1.04, 1.12, 1.23, 1.36, 1.4, 1.42, 1.4, 1.21, 1.04, 1.02, 1.01, 1.0, 1.01, 1.0, 0.95, 0.92, 0.87, 0.79, 0.72, 0.66, 0.64, 0.63, 0.64, 0.73, 0.85, 0.95, 0.99, 1.0, 1.02, 1.02, 1.01, 1.02, 1.0, 0.99, 1.0, 1.04, 1.09, 1.12, 1.19, 1.41, 1.65, 1.7, 1.63, 1.58, 1.43, 1.17, 0.99, 0.98, 1.08, 1.14, 1.06, 0.97, 0.96, 0.92, 0.8, 0.66, 0.57, 0.53, 0.55], Y: [-0.18, -0.21, -0.16, -0.14, -0.16, -0.19, -0.23, -0.24, -0.23, -0.16, -0.08, -0.05, -0.14, -0.23, -0.19, -0.18, -0.21, -0.23, -0.33, -0.41, -0.35, -0.32, -0.38, -0.43, -0.49, -0.5, -0.43, -0.38, -0.33, -0.28, -0.24, -0.16, -0.13, -0.17, -0.18, -0.2, -0.2, -0.19, -0.21, -0.23, -0.24, -0.18, -0.07, -0.03, -0.06, -0.06, -0.03, -0.02, -0.03, -0.02, -0.04, -0.09, -0.17, -0.19, -0.13, -0.14, -0.24, -0.35, -0.44, -0.52, -0.52, -0.42, -0.38, -0.37, -0.33, -0.39, -0.39, -0.32, -0.27, -0.2, -0.16, -0.11, -0.08, -0.13, -0.12], Z: [0.05, 0.07, 0.11, 0.09, 0.08, 0.14, 0.2, 0.25, 0.26, 0.26, 0.26, 0.22, 0.19, 0.23, 0.25, 0.22, 0.17, 0.15, 0.19, 0.26, 0.29, 0.31, 0.32, 0.26, 0.18, 0.12, 0.08, 0.1, 0.1, 0.06, 0.05, 0.06, 0.07, 0.06, 0.05, 0.04, -0.0, -0.01, 0.01, 0.02, 0.03, 0.04, 0.04, 0.03, 0.01, 0.03, 0.06, 0.07, 0.06, 0.04, 0.03, 0.03, 0.02, 0.02, -0.0, -0.06, -0.1, -0.07, -0.03, -0.01, -0.03, -0.07, -0.07, -0.02, 0.02, 0.03, 0.05, 0.08, 0.07, 0.02, 0.01, 0.01, -0.0, 0.0, 0.02]',\n",
       " 'STANDING': 'X: [0.64, 0.67, 0.69, 0.72, 0.82, 0.91, 0.96, 0.97, 0.92, 0.87, 0.83, 0.88, 0.97, 1.02, 1.02, 1.0, 1.04, 1.12, 1.23, 1.36, 1.4, 1.42, 1.4, 1.21, 1.04, 1.02, 1.01, 1.0, 1.01, 1.0, 0.95, 0.92, 0.87, 0.79, 0.72, 0.66, 0.64, 0.63, 0.64, 0.73, 0.85, 0.95, 0.99, 1.0, 1.02, 1.02, 1.01, 1.02, 1.0, 0.99, 1.0, 1.04, 1.09, 1.12, 1.19, 1.41, 1.65, 1.7, 1.63, 1.58, 1.43, 1.17, 0.99, 0.98, 1.08, 1.14, 1.06, 0.97, 0.96, 0.92, 0.8, 0.66, 0.57, 0.53, 0.55], Y: [-0.18, -0.21, -0.16, -0.14, -0.16, -0.19, -0.23, -0.24, -0.23, -0.16, -0.08, -0.05, -0.14, -0.23, -0.19, -0.18, -0.21, -0.23, -0.33, -0.41, -0.35, -0.32, -0.38, -0.43, -0.49, -0.5, -0.43, -0.38, -0.33, -0.28, -0.24, -0.16, -0.13, -0.17, -0.18, -0.2, -0.2, -0.19, -0.21, -0.23, -0.24, -0.18, -0.07, -0.03, -0.06, -0.06, -0.03, -0.02, -0.03, -0.02, -0.04, -0.09, -0.17, -0.19, -0.13, -0.14, -0.24, -0.35, -0.44, -0.52, -0.52, -0.42, -0.38, -0.37, -0.33, -0.39, -0.39, -0.32, -0.27, -0.2, -0.16, -0.11, -0.08, -0.13, -0.12], Z: [0.05, 0.07, 0.11, 0.09, 0.08, 0.14, 0.2, 0.25, 0.26, 0.26, 0.26, 0.22, 0.19, 0.23, 0.25, 0.22, 0.17, 0.15, 0.19, 0.26, 0.29, 0.31, 0.32, 0.26, 0.18, 0.12, 0.08, 0.1, 0.1, 0.06, 0.05, 0.06, 0.07, 0.06, 0.05, 0.04, -0.0, -0.01, 0.01, 0.02, 0.03, 0.04, 0.04, 0.03, 0.01, 0.03, 0.06, 0.07, 0.06, 0.04, 0.03, 0.03, 0.02, 0.02, -0.0, -0.06, -0.1, -0.07, -0.03, -0.01, -0.03, -0.07, -0.07, -0.02, 0.02, 0.03, 0.05, 0.08, 0.07, 0.02, 0.01, 0.01, -0.0, 0.0, 0.02]',\n",
       " 'WALKING': 'X: [0.64, 0.67, 0.69, 0.72, 0.82, 0.91, 0.96, 0.97, 0.92, 0.87, 0.83, 0.88, 0.97, 1.02, 1.02, 1.0, 1.04, 1.12, 1.23, 1.36, 1.4, 1.42, 1.4, 1.21, 1.04, 1.02, 1.01, 1.0, 1.01, 1.0, 0.95, 0.92, 0.87, 0.79, 0.72, 0.66, 0.64, 0.63, 0.64, 0.73, 0.85, 0.95, 0.99, 1.0, 1.02, 1.02, 1.01, 1.02, 1.0, 0.99, 1.0, 1.04, 1.09, 1.12, 1.19, 1.41, 1.65, 1.7, 1.63, 1.58, 1.43, 1.17, 0.99, 0.98, 1.08, 1.14, 1.06, 0.97, 0.96, 0.92, 0.8, 0.66, 0.57, 0.53, 0.55], Y: [-0.18, -0.21, -0.16, -0.14, -0.16, -0.19, -0.23, -0.24, -0.23, -0.16, -0.08, -0.05, -0.14, -0.23, -0.19, -0.18, -0.21, -0.23, -0.33, -0.41, -0.35, -0.32, -0.38, -0.43, -0.49, -0.5, -0.43, -0.38, -0.33, -0.28, -0.24, -0.16, -0.13, -0.17, -0.18, -0.2, -0.2, -0.19, -0.21, -0.23, -0.24, -0.18, -0.07, -0.03, -0.06, -0.06, -0.03, -0.02, -0.03, -0.02, -0.04, -0.09, -0.17, -0.19, -0.13, -0.14, -0.24, -0.35, -0.44, -0.52, -0.52, -0.42, -0.38, -0.37, -0.33, -0.39, -0.39, -0.32, -0.27, -0.2, -0.16, -0.11, -0.08, -0.13, -0.12], Z: [0.05, 0.07, 0.11, 0.09, 0.08, 0.14, 0.2, 0.25, 0.26, 0.26, 0.26, 0.22, 0.19, 0.23, 0.25, 0.22, 0.17, 0.15, 0.19, 0.26, 0.29, 0.31, 0.32, 0.26, 0.18, 0.12, 0.08, 0.1, 0.1, 0.06, 0.05, 0.06, 0.07, 0.06, 0.05, 0.04, -0.0, -0.01, 0.01, 0.02, 0.03, 0.04, 0.04, 0.03, 0.01, 0.03, 0.06, 0.07, 0.06, 0.04, 0.03, 0.03, 0.02, 0.02, -0.0, -0.06, -0.1, -0.07, -0.03, -0.01, -0.03, -0.07, -0.07, -0.02, 0.02, 0.03, 0.05, 0.08, 0.07, 0.02, 0.01, 0.01, -0.0, 0.0, 0.02]'}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: LAYING\n",
      "Prediction:  Based on the accelerometer data provided, the activity is likely 'LAYING'. The X-axis values are relatively stable and close to zero, indicating minimal movement in the horizontal direction. The Y-axis values are also relatively stable, with a slight increase and decrease, but overall, they are close to zero. The Z-axis values show a slight increase and decrease, but again, they are close to zero. This suggests that the person is lying down and not moving much.\n",
      "\n",
      "Ground Truth: SITTING\n",
      "Prediction:  Based on the accelerometer data provided, the activity is likely 'LAYING'. The X-axis values are relatively constant, indicating minimal movement in the horizontal direction. The Y-axis values also show minimal variation, suggesting that the person is not moving up or down. The Z-axis values show a slight variation, but it is not significant enough to indicate any specific activity. The overall pattern of the data suggests that the person is in a stationary position, which is consistent with the activity of 'LAYING'.\n",
      "\n",
      "Ground Truth: STANDING\n",
      "Prediction:  Based on the accelerometer data provided, the activity is likely 'LAYING'. The X-axis values are relatively constant and high, indicating minimal movement in the horizontal direction. The Y-axis values are also relatively constant and low, indicating minimal movement in the vertical direction. The Z-axis values are relatively constant and moderate, indicating some movement in the vertical direction, but not enough to suggest any significant activity. The overall pattern of the data suggests a person lying down with minimal movement.\n",
      "\n",
      "Ground Truth: WALKING\n",
      "Prediction:  Based on the accelerometer data provided, the activity is likely 'WALKING'. The data shows a mix of low and high values in the X and Y directions, with a slight increase in the Z direction, which is consistent with walking. The values in the X direction show a range of 0.68 to 1.49, which is typical for walking. The values in the Y direction show a range of -0.71 to 0.04, which is also typical for walking. The values in the Z direction show a range of -0.26 to 0.28, which is consistent with walking.\n",
      "\n",
      "Ground Truth: WALKING_DOWNSTAIRS\n",
      "Prediction:  Based on the accelerometer data provided, the activity is likely 'WALKING'. The data shows a mix of high and low values in the X and Y directions, with a slight increase in the Z direction, which is consistent with walking. The values in the X direction are generally higher than those in the Y direction, which is also consistent with walking. Additionally, the data shows a mix of positive and negative values in the Y direction, which is also consistent with walking.\n",
      "\n",
      "Ground Truth: WALKING_UPSTAIRS\n",
      "Prediction:  Based on the provided accelerometer data, the activity is likely 'LAYING'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for prompt in prompts:\n",
    "  combined_keys = {**system_prompt, **prompt['data']}\n",
    "  answer = chain.invoke(combined_keys)\n",
    "  print(\"Ground Truth:\", prompt['value'])\n",
    "  print(\"Prediction: \", answer.content)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few-Shot Learning performs better because the model has some context for the task. This is due to the model being better tuned to the specific patterns in the few provided examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3\n",
    "\n",
    "Since zero-shot learning relies on the model's general knowledge, it might not perform well when the task involves nuanced or highly specific data, such as classifying activities based on accelerometer readings without any prior examples. In scenarios where the model doesn't have enough contextual information, it may misinterpret the input, leading to inaccurate predictions.\n",
    "\n",
    "The performance of few-shot learning heavily depends on the quality and representativeness of the examples provided. If the examples are not diverse or comprehensive enough, the model's predictions may still be less robust compared to a fully trained model. Despite these limitations, few-shot learning is generally more effective than zero-shot learning for tasks requiring specific domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4\n",
    "\n",
    "New activity not seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing some of the activity class exmaples in the examples\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are provided with accelerometer data in the X, Y, and Z directions, recorded during different human activities. The activities can be one of the following: 'LAYING', 'SITTING', 'STANDING', 'WALKING', 'WALKING_DOWNSTAIRS', or 'WALKING_UPSTAIRS'. Based on the input data from these three axes, predict the corresponding activity label without additional explanation. No code is to be produced for this, rather the final activity label only based on the analysis from the different directional accelerometer data. Here are a few examples:\"),\n",
    "    (\"system\", \"Example 1 - Activity: LAYING, {LAYING}\"),\n",
    "    (\"system\", \"Example 2 - Activity: SITTING, {SITTING}\"),\n",
    "    (\"system\", \"Example 3 - Activity: WALKING_DOWNSTAIRS, {WALKING_DOWNSTAIRS}\"),\n",
    "    (\"system\", \"Example 4 - Activity: WALKING_UPSTAIRS, {WALKING_UPSTAIRS}\"),\n",
    "    (\"user\", \"The accelerometer readings are: X: {x_data}, Y: {y_data}, Z: {z_data}. What activity does this data represent?\")\n",
    "])\n",
    "\n",
    "chain = chat_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: STANDING\n",
      "Prediction:  Based on the accelerometer data provided, the activity is likely 'LAYING'.\n",
      "\n",
      "Ground Truth: WALKING\n",
      "Prediction:  Based on the accelerometer data provided, the activity is likely 'WALKING'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "del system_prompt['STANDING']\n",
    "del system_prompt['WALKING']\n",
    "\n",
    "for prompt in prompts[2:4]:\n",
    "  combined_keys = {**system_prompt, **prompt['data']}\n",
    "  answer = chain.invoke(combined_keys)\n",
    "  print(\"Ground Truth:\", prompt['value'])\n",
    "  print(\"Prediction: \", answer.content)\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the model does not perform well on the data not seen before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_data = {\n",
    "    'x_data': [0.63, 0.65, 0.68, 0.71, 0.81, 0.89, 0.94, 0.95, 0.91, 0.86, 0.82, 0.87, 0.96, 1.01, 1.01, 0.99, 1.03, 1.1, 1.21, 1.33, 1.38, 1.4, 1.38, 1.19, 1.02, 1.0, 0.99, 0.98, 0.99, 0.98, 0.93, 0.9, 0.85, 0.77, 0.7, 0.64, 0.62, 0.61, 0.62, 0.71, 0.83, 0.93, 0.97, 0.98, 1.0, 1.0, 0.99, 1.0, 0.98, 0.97, 0.98, 1.02, 1.07, 1.1, 1.17, 1.39, 1.63, 1.68, 1.61, 1.56, 1.41, 1.15, 0.97, 0.96, 1.06, 1.12, 1.04, 0.95, 0.94, 0.9, 0.78, 0.64, 0.55, 0.51, 0.53],\n",
    "    'y_data': [-0.19, -0.22, -0.17, -0.15, -0.17, -0.2, -0.24, -0.25, -0.24, -0.17, -0.09, -0.06, -0.15, -0.24, -0.2, -0.19, -0.22, -0.24, -0.34, -0.42, -0.36, -0.33, -0.39, -0.44, -0.5, -0.51, -0.44, -0.39, -0.34, -0.29, -0.25, -0.17, -0.14, -0.18, -0.19, -0.21, -0.21, -0.2, -0.22, -0.24, -0.25, -0.19, -0.08, -0.04, -0.07, -0.07, -0.04, -0.03, -0.04, -0.03, -0.05, -0.1, -0.18, -0.2, -0.14, -0.15, -0.25, -0.36, -0.45, -0.53, -0.53, -0.43, -0.39, -0.38, -0.34, -0.4, -0.4, -0.33, -0.28, -0.21, -0.17, -0.12, -0.09, -0.14, -0.13],\n",
    "    'z_data': [0.06, 0.08, 0.12, 0.1, 0.09, 0.15, 0.21, 0.26, 0.27, 0.27, 0.27, 0.23, 0.2, 0.24, 0.26, 0.23, 0.18, 0.16, 0.2, 0.27, 0.3, 0.32, 0.33, 0.27, 0.19, 0.13, 0.09, 0.11, 0.11, 0.07, 0.06, 0.07, 0.08, 0.07, 0.06, 0.05, 0.01, 0.0, 0.02, 0.03, 0.04, 0.05, 0.05, 0.04, 0.02, 0.04, 0.07, 0.08, 0.07, 0.05, 0.04, 0.04, 0.03, 0.03, 0.01, -0.05, -0.09, -0.06, -0.02, 0.0, -0.02, -0.06, -0.06, -0.01, 0.03, 0.04, 0.06, 0.09, 0.08, 0.03, 0.02, 0.02, 0.01, 0.01, 0.03]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground Truth: Random Activity Data\n",
      "Prediction:  Based on the accelerometer data provided, the activity is likely 'STANDING'. The data shows a relatively consistent pattern in the X, Y, and Z directions, with some minor fluctuations. The values in the X direction are generally increasing and then decreasing, which is consistent with a standing activity. The Y direction values are also relatively consistent, with some minor fluctuations. The Z direction values show a slight increase and then decrease, which is also consistent with a standing activity. Overall, the data suggests that the person is standing still, with some minor movements.\n"
     ]
    }
   ],
   "source": [
    "combined_keys = {**system_prompt, **rand_data}\n",
    "answer = chain.invoke(combined_keys)\n",
    "print(\"Ground Truth: Random Activity Data\")\n",
    "print(\"Prediction: \", answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
